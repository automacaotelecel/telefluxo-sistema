import pandas as pd
import requests
import os
import re
from typing import List, Dict, Any

# ‚úÖ ADICIONADO
import time

# --- CONFIGURA√á√ïES ---
CAMINHO_EXCEL = r"C:\Users\Usuario\Desktop\BI AUTOMATICO\BI_SAMSUNG\Vendas_Diarias_2.0.xlsm"
URL_BACKEND = "https://telefluxo-aplicacao.onrender.com"

TIMEOUT = (10, 180)  # (conex√£o, resposta) em segundos

# ‚úÖ ADICIONADO: pol√≠tica de retry
RETRY_STATUS = {502, 503, 504}
MAX_RETRIES = 6  # aumentei para aguentar Render/lock (n√£o remove nada, s√≥ adiciona)
BASE_WAIT_SECONDS = 8  # backoff base


# ===== MAPA DE LOJAS (CNPJ -> NOME) =====
LOJAS_MAP = {
    "12309173001309": "ARAGUAIA SHOPPING",
    "12309173000418": "BOULEVARD SHOPPING",
    "12309173000175": "BRASILIA SHOPPING",
    "12309173000680": "CONJUNTO NACIONAL",
    "12309173001228": "CONJUNTO NACIONAL QUIOSQUE",
    "12309173000507": "GOIANIA SHOPPING",
    "12309173000256": "IGUATEMI SHOPPING",
    "12309173000841": "JK SHOPPING",
    "12309173000337": "PARK SHOPPING",
    "12309173000922": "PATIO BRASIL",
    "12309173000760": "TAGUATINGA SHOPPING",
    "12309173001147": "TERRA√áO SHOPPING",
    "12309173001651": "TAGUATINGA SHOPPING QQ",
    "12309173001732": "UBERL√ÇNDIA SHOPPING",
    "12309173001813": "UBERABA SHOPPING",
    "12309173001570": "FLAMBOYANT SHOPPING",
    "12309173002119": "BURITI SHOPPING",
    "12309173002461": "PASSEIO DAS AGUAS",
    "12309173002038": "PORTAL SHOPPING",
    "12309173002208": "SHOPPING SUL",
    "12309173001902": "BURITI RIO VERDE",
    "12309173002380": "PARK ANAPOLIS",
    "12309173002542": "SHOPPING RECIFE",
    "12309173002895": "MANAIRA SHOPPING",
    "12309173002976": "IGUATEMI FORTALEZA",
    "12309173001066": "CD TAGUATINGA",
}

# ‚úÖ [NOVO] LISTA DE CORRE√á√ÉO MANUAL (BLINDAGEM)
# Garante que nomes errados do Excel virem nomes certos do Sistema
CORRECAO_NOMES = {
    "UBERABA": "UBERABA SHOPPING",
    "UBERL√ÇNDIA": "UBERL√ÇNDIA SHOPPING",
    "UBERLANDIA": "UBERL√ÇNDIA SHOPPING",
    "CNB SHOPPING": "CONJUNTO NACIONAL",
    "CNB QUIOSQUE": "CONJUNTO NACIONAL QUIOSQUE",
    "QQ TAGUATINGA SHOPPING": "TAGUATINGA SHOPPING QQ",
    "ESTOQUE CD": "CD TAGUATINGA",
    "CD": "CD TAGUATINGA",
    "PASSEIO DAS √ÅGUAS": "PASSEIO DAS AGUAS",
    "TERRACO SHOPPING": "TERRA√áO SHOPPING",
    "PARK": "PARK SHOPPING"
}

def norm(s: Any) -> str:
    s = "" if s is None else str(s)
    s = s.strip().upper()
    s = re.sub(r"\s+", " ", s)
    return s


# Reverse map: NOME -> CNPJ
REVERSE_LOJAS = {norm(nome): cnpj for cnpj, nome in LOJAS_MAP.items()}

# Aliases (nomes que aparecem no Excel -> nome oficial do mapa)
ALIASES = {
    "ESTOQUE CD": "CD TAGUATINGA",
    "CD": "CD TAGUATINGA",
    "UBERL√ÇNDIA": "UBERL√ÇNDIA SHOPPING",
    "UBERLANDIA": "UBERL√ÇNDIA SHOPPING",
    "UBERABA": "UBERABA SHOPPING",
    "CNB SHOPPING": "CONJUNTO NACIONAL",
    "CNB QUIOSQUE": "CONJUNTO NACIONAL QUIOSQUE",
    "QQ TAGUATINGA SHOPPING": "TAGUATINGA SHOPPING QQ",
    "PASSEIO DAS √ÅGUAS": "PASSEIO DAS AGUAS",
    "TERRACO SHOPPING": "TERRA√áO SHOPPING",
}
ALIASES_N = {norm(k): norm(v) for k, v in ALIASES.items()}


def loja_para_cnpj(loja: Any) -> str | None:
    """
    Converte o nome da loja vindo do Excel (LOJA SISTEMA / NOME_FANTASIA)
    para CNPJ limpo, baseado no mapa.
    """
    t = norm(loja)
    
    # ‚úÖ [CORRE√á√ÉO 1] Verifica a lista manual primeiro
    if t in CORRECAO_NOMES:
        t = CORRECAO_NOMES[t]

    # Remove prefixos comuns
    for prefix in ["SAMSUNG - MRF - ", "SSG "]:
        if t.startswith(prefix):
            t = norm(t[len(prefix):])

    # Aplica aliases
    t = ALIASES_N.get(t, t)

    return REVERSE_LOJAS.get(t)

# ‚úÖ [NOVO] FUN√á√ÉO DE LIMPEZA DE NOME
def get_clean_store_name(raw_name: Any) -> str:
    """Fun√ß√£o Mestra para limpar nomes de lojas antes de salvar"""
    nome_sujo = norm(raw_name)
    
    # 1. Verifica Corre√ß√£o Manual Direta (Mais confi√°vel)
    if nome_sujo in CORRECAO_NOMES:
        return CORRECAO_NOMES[nome_sujo]
    
    # 2. Verifica se j√° √© um nome oficial (ex: PARK SHOPPING)
    if nome_sujo in REVERSE_LOJAS:
        return LOJAS_MAP[REVERSE_LOJAS[nome_sujo]]
        
    # 3. Tenta via CNPJ (Fallback)
    cnpj = loja_para_cnpj(nome_sujo)
    if cnpj and cnpj in LOJAS_MAP:
        return LOJAS_MAP[cnpj]
        
    return nome_sujo # Retorna o original se n√£o achar nada


def limpar_valores_json(dados: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Converte NaN/NaT para None."""
    cleaned = []
    for row in dados:
        new_row = {}
        for k, v in row.items():
            if pd.isna(v):
                new_row[k] = None
            else:
                new_row[k] = v
        cleaned.append(new_row)
    return cleaned


def enviar_dados_para_api(endpoint: str, dados: List[Dict[str, Any]]) -> bool:
    url = f"{URL_BACKEND}{endpoint}"

    if not isinstance(dados, list):
        print("‚ùå ERRO: dados n√£o √© uma lista.")
        return False

    if len(dados) == 0:
        print(f"‚ö†Ô∏è Nenhum registro para enviar em {endpoint}.")
        return True

    dados = limpar_valores_json(dados)

    print(f"üì° Enviando {len(dados)} registros para: {url}...")

    # ‚úÖ ADICIONADO: retry com backoff para TIMEOUT/502/503/504/SQLITE_BUSY
    headers = {"Content-Type": "application/json"}

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            response = requests.post(url, json=dados, headers=headers, timeout=TIMEOUT)

            # ‚úÖ Sucesso: qualquer 2xx
            if 200 <= response.status_code < 300:
                try:
                    payload = response.json()
                    msg = payload.get("message") if isinstance(payload, dict) else payload
                except Exception:
                    msg = response.text[:300]
                print(f"‚úÖ Sucesso ({response.status_code}) - {msg}")
                return True

            # ‚úÖ Se vier 502/503/504, tenta novamente
            if response.status_code in RETRY_STATUS:
                wait = BASE_WAIT_SECONDS * attempt
                print(
                    f"‚ö†Ô∏è Servidor inst√°vel/ocupado ({response.status_code}). "
                    f"Tentando novamente em {wait}s... (tentativa {attempt}/{MAX_RETRIES})"
                )
                time.sleep(wait)
                continue

            # ‚úÖ Se o backend devolver SQLITE_BUSY em texto (caso voc√™ trate e devolva mensagem)
            if "SQLITE_BUSY" in (response.text or "") or "database is locked" in (response.text or ""):
                wait = BASE_WAIT_SECONDS * attempt
                print(
                    f"‚ö†Ô∏è Banco ocupado (SQLITE_BUSY). "
                    f"Tentando novamente em {wait}s... (tentativa {attempt}/{MAX_RETRIES})"
                )
                time.sleep(wait)
                continue

            # ‚ùå Falha definitiva (outros status)
            print(f"‚ùå Falha ({response.status_code}) - {response.text[:800]}")
            return False

        except requests.exceptions.Timeout:
            wait = BASE_WAIT_SECONDS * attempt
            print(
                f"‚ö†Ô∏è Timeout: o servidor demorou para responder. "
                f"Tentando novamente em {wait}s... (tentativa {attempt}/{MAX_RETRIES})"
            )
            time.sleep(wait)
            continue

        except requests.exceptions.ConnectionError as e:
            wait = BASE_WAIT_SECONDS * attempt
            print(
                f"‚ö†Ô∏è Erro de conex√£o: {e}. "
                f"Tentando novamente em {wait}s... (tentativa {attempt}/{MAX_RETRIES})"
            )
            time.sleep(wait)
            continue

        except Exception as e:
            print(f"‚ùå Erro inesperado: {e}")
            return False

    print("‚ùå Falha: excedeu o n√∫mero de tentativas.")
    return False


def integrar_vendas_geral():
    # Verifica se arquivo existe
    if not os.path.exists(CAMINHO_EXCEL):
        print("‚ùå Arquivo Excel n√£o encontrado.")
        return False

    print("üìä Lendo Excel (Aba VENDAS)...")
    try:
        df = pd.read_excel(CAMINHO_EXCEL, sheet_name="VENDAS", engine="openpyxl")
    except Exception as e:
        print(f"‚ùå Erro leitura Excel VENDAS: {e}")
        return False

    print(f"üìå Linhas lidas (bruto): {len(df)}")

    # Remove canceladas
    if "CANCELADO" in df.columns:
        df = df[df["CANCELADO"].astype(str).str.strip().str.upper() == "N"].copy()
        print(f"üìå Linhas ap√≥s remover canceladas: {len(df)}")

    # Defini√ß√£o das colunas (apenas para refer√™ncia, pois vamos for√ßar a S)
    col_data = "DATA_EMISSAO"
    col_vendedor = "NOME_VENDEDOR"
    col_desc = "DESCRICAO"
    col_qtd = "QUANTIDADE" if "QUANTIDADE" in df.columns else "QTD REAL"
    col_loja = "LOJA SISTEMA" if "LOJA SISTEMA" in df.columns else "NOME_FANTASIA"
    col_familia = "CATEGORIA REAL" if "CATEGORIA REAL" in df.columns else "CATEGORIA"
    col_regiao = "REGIAO"

    try:
        # 1. CRIA A TABELA PRIMEIRO (Isso resolve o seu erro)
        treated = pd.DataFrame()

        # 2. PREENCHE AS COLUNAS PADR√ÉO
        treated["data_emissao"] = pd.to_datetime(df[col_data], dayfirst=True, errors="coerce")
        treated = treated.dropna(subset=["data_emissao"])
        treated["data_emissao"] = treated["data_emissao"].dt.strftime("%Y-%m-%d")

        treated["nome_vendedor"] = df[col_vendedor].astype(str).str.strip().str.upper()
        treated["descricao"] = df[col_desc].astype(str).str.strip().str.upper()
        
        # Quantidade
        treated["quantidade"] = pd.to_numeric(df[col_qtd], errors="coerce").fillna(0)

        # -----------------------------------------------------------
        # üéØ AQUI EST√Å A CORRE√á√ÉO: COLUNA S (√çndice 18)
        # -----------------------------------------------------------
        print(f"üéØ Usando coluna S (√≠ndice 18) para VALOR REAL...")
        treated["total_liquido"] = pd.to_numeric(df.iloc[:, 18], errors="coerce").fillna(0)
        # -----------------------------------------------------------

        # Mapeamento de Loja -> CNPJ
        # ‚úÖ [CORRE√á√ÉO 2] Usa a fun√ß√£o que j√° tem a corre√ß√£o de nomes
        treated["cnpj_empresa"] = df[col_loja].map(loja_para_cnpj)

        # Fam√≠lia e Regi√£o
        treated["familia"] = df[col_familia].astype(str).str.strip().str.upper()
        treated["regiao"] = df[col_regiao].astype(str).str.strip().str.upper()

        # Filtra linhas inv√°lidas
        treated = treated.dropna(subset=["cnpj_empresa"])
        treated = treated[
            (treated["total_liquido"] > 0.01) | (treated["quantidade"] > 0.001)
        ].copy()

        print(f"‚úÖ Linhas prontas para enviar: {len(treated)}")

    except Exception as e:
        print(f"‚ùå Erro tratamento VENDAS: {e}")
        return False

    # Envia para a API
    dados_json = treated.to_dict(orient="records")
    ok = enviar_dados_para_api("/api/sync/vendas", dados_json)

    if ok:
        print("‚úÖ Vendas enviadas e sincronizadas com sucesso.")
        time.sleep(5) # Pausa de seguran√ßa
        return True
    else:
        print("‚ùå Falha ao enviar vendas.")
        return False


def integrar_kpi_vendedores():
    print("üèÜ Calculando KPIs Reais (A partir da aba VENDAS)...")
    
    # 1. Carrega as duas abas
    try:
        df_vendas = pd.read_excel(CAMINHO_EXCEL, sheet_name="VENDAS", engine="openpyxl")
        df_meta = pd.read_excel(CAMINHO_EXCEL, sheet_name="API VENDEDORES", engine="openpyxl")
    except Exception as e:
        print(f"‚ùå Erro leitura Excel: {e}")
        return False

    # 2. Prepara a base de Vendas (Raw Data)
    # Garante que estamos lendo a Coluna S (Total Real) e Qtd Real
    col_vendedor = "NOME_VENDEDOR"
    col_loja = "LOJA SISTEMA" if "LOJA SISTEMA" in df_vendas.columns else "NOME_FANTASIA"
    
    # Limpeza b√°sica
    df_vendas = df_vendas[df_vendas["CANCELADO"].astype(str).str.upper() == "N"].copy()
    
    # For√ßa convers√£o num√©rica
    df_vendas["total_real"] = pd.to_numeric(df_vendas.iloc[:, 18], errors="coerce").fillna(0) # Coluna S
    df_vendas["qtd_real"] = pd.to_numeric(df_vendas["QTD REAL"], errors="coerce").fillna(0)
    
    # Agrupa por Vendedor para ter os N√∫meros Reais
    # Conta NF distintas para Ticket M√©dio e PA
    kpi_real = df_vendas.groupby(col_vendedor).agg({
        "total_real": "sum",
        "qtd_real": "sum",
        col_loja: "first", # Pega a loja do vendedor
        "NOTA_FISCAL": pd.Series.nunique, # Conta notas √∫nicas para PA/Ticket
        "REGIAO": "first"
    }).reset_index()

    # 3. Prepara a base de Metas/Anterior (Do Excel API VENDEDORES)
    # Vamos pegar apenas o que n√£o conseguimos calcular: Fat Anterior e % Crescimento Estimado
    df_meta_clean = pd.DataFrame()
    df_meta_clean["vendedor"] = df_meta.iloc[:, 1].astype(str).str.strip().str.upper() # Col B
    df_meta_clean["fat_anterior"] = pd.to_numeric(df_meta.iloc[:, 4], errors="coerce").fillna(0) # Col E
    df_meta_clean["pct_seguro"] = pd.to_numeric(df_meta.iloc[:, 18], errors="coerce").fillna(0) # Col S (% Seguro)

    # 4. Cruza as informa√ß√µes (Merge)
    # Usa os dados calculados (Real) e complementa com o Excel (Meta/Anterior)
    df_final = pd.merge(kpi_real, df_meta_clean, left_on=col_vendedor, right_on="vendedor", how="left")
    
    # 5. Monta o JSON Final
    output_list = []
    
    # Debug: Verificar lojas corrigidas
    lojas_salvas = set()

    for _, row in df_final.iterrows():
        vendedor = str(row[col_vendedor]).strip().upper()
        if vendedor == "NAN" or vendedor == "NONE": continue

        # --- AQUI √â O PULO DO GATO: LIMPAR O NOME DA LOJA ---
        # ‚úÖ [CORRE√á√ÉO 3] Usando a nova fun√ß√£o blindada get_clean_store_name
        nome_loja_sujo = str(row[col_loja])
        nome_loja_limpo = get_clean_store_name(nome_loja_sujo)
        
        # Guarda para debug no console
        if nome_loja_limpo != nome_loja_sujo.strip().upper():
            lojas_salvas.add(f"{nome_loja_sujo} -> {nome_loja_limpo}")
        # ----------------------------------------------------

        # C√°lculos de KPI
        total = float(row["total_real"])
        qtd = int(row["qtd_real"])
        num_nf = int(row["NOTA_FISCAL"]) if row["NOTA_FISCAL"] > 0 else 1
        
        # Ticket M√©dio e PA Calculados na hora (Mais confi√°vel que o Excel)
        ticket = total / num_nf if num_nf > 0 else 0
        pa = qtd / num_nf if num_nf > 0 else 0
        
        # Dados Hist√≥ricos (do Excel)
        anterior = float(row["fat_anterior"]) if not pd.isna(row["fat_anterior"]) else 0
        
        # C√°lculo de Crescimento vs M√™s Anterior
        crescimento = ((total - anterior) / anterior) if anterior > 0 else 0

        output_list.append({
            "loja": nome_loja_limpo,     # ‚úÖ AGORA SALVA O NOME LIMPO
            "vendedor": vendedor,
            "fat_atual": total,          
            "tendencia": 0,
            "fat_anterior": anterior,    
            "crescimento": crescimento,
            "pa": pa,
            "ticket": ticket,
            "qtd": qtd,
            "regiao": str(row["REGIAO"]).upper(),
            "pct_seguro": float(row["pct_seguro"]),
            "seguros": 0
        })

    # Envia
    print("üîé DEBUG: Exemplos de lojas corrigidas:")
    for l in list(lojas_salvas)[:5]: 
        print(f"   {l}")

    print(f"üìä Processados {len(output_list)} vendedores com dados reais.")
    ok = enviar_dados_para_api("/api/sync/vendedores", output_list)

    if ok:
        print("‚úÖ KPIs Reais calculados e sincronizados!")
        return True
    else:
        print("‚ùå Falha ao enviar KPIs.")
        return False


if __name__ == "__main__":
    if not URL_BACKEND.startswith("http"):
        print("‚ùå ERRO: URL_BACKEND inv√°lida.")
    else:
        # ‚úÖ ADICIONADO: s√≥ envia KPI se vendas estiver OK
        ok_vendas = integrar_vendas_geral()
        if ok_vendas:
            integrar_kpi_vendedores()
        else:
            print("‚ö†Ô∏è KPI n√£o foi enviado porque VENDAS n√£o confirmou sucesso (evita SQLITE_BUSY/lock).")